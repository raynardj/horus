{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseNet Application of Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torchvision.models.densenet import densenet121 as feature_extractor\n",
    "from torch import nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SCALE = 256\n",
    "TRAIN = \"/data/avatar/train/\"\n",
    "VALID = \"/data/avatar/test/\"\n",
    "CUDA = torch.cuda.is_available()\n",
    "DENSE_FEATURE = 1024\n",
    "BS = 32\n",
    "VERSION = \"0.0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangxiaochen/anaconda3/lib/python3.6/site-packages/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight.data)\n"
     ]
    }
   ],
   "source": [
    "conv_model = feature_extractor(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split ConvLayer to 2 parts, conv0~transtition3, (not gonna train), denseblock4~norm5 (train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dense_conv1 = nn.Sequential(*[getattr(conv_model.features,nn_name) for nn_name in [\"conv0\",\"norm0\",\"relu0\",\"pool0\",\"denseblock1\",\"transition1\",\n",
    "                                                                                   \"denseblock2\",\"transition2\",\"denseblock3\",\"transition3\",]])\n",
    "\n",
    "dense_conv2 = nn.Sequential(*[getattr(conv_model.features,nn_name) for nn_name in [\"denseblock4\",\"norm5\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.RandomAffine([-10,10]), \n",
    "                                transforms.Resize((SCALE,SCALE)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([.5,.5,.5],[.5,.5,.5]),\n",
    "                               ])\n",
    "\n",
    "trn = ImageFolder(TRAIN,transform=transform)\n",
    "val = ImageFolder(VALID,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'erotic', 1: 'normal', 2: 'poli', 3: 'porn', 4: 'qr', 5: 'w_normal', 6: 'w_risk'}\n"
     ]
    }
   ],
   "source": [
    "CLASS_TO_IDX = trn.class_to_idx\n",
    "IDX_TO_CLASS = dict((v,k) for k,v in CLASS_TO_IDX.items())\n",
    "print(IDX_TO_CLASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_gen = iter(DataLoader(trn,shuffle=True))\n",
    "\n",
    "# next(data_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top half of the model, with fully connected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flatten,self).__init__()\n",
    "    def forward(self,x):\n",
    "        bs = x.size()[0]\n",
    "        return x.view(bs,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n"
     ]
    }
   ],
   "source": [
    "fl = Flatten()\n",
    "avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "FEATURE_WIDTH = fl(avg_pool(dense_conv2(dense_conv1(torch.rand(2,3,SCALE,SCALE))))).size()[1]\n",
    "print(FEATURE_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class top_half(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(top_half,self).__init__()\n",
    "        self.top_ = nn.Sequential(*[nn.AdaptiveAvgPool2d((1,1)),Flatten(),\n",
    "                                   nn.Linear(FEATURE_WIDTH,DENSE_FEATURE,bias=False),\n",
    "                                    nn.BatchNorm1d(DENSE_FEATURE),\n",
    "                                    nn.LeakyReLU(inplace=True),\n",
    "                                    nn.Dropout(p=.5),\n",
    "                                    nn.Linear(DENSE_FEATURE,len(CLASS_TO_IDX),bias=True),\n",
    "                                   ])\n",
    "    def forward(self,x):\n",
    "        return F.softmax(self.top_(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Model, optimizer,train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_half_ = top_half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if CUDA:\n",
    "    top_half_.cuda()\n",
    "    dense_conv1.cuda()\n",
    "    dense_conv2.cuda()\n",
    "    \n",
    "from torch.optim import Adam\n",
    "\n",
    "opt = Adam(list(dense_conv2.parameters())+list(top_half_.parameters()),amsgrad=True)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from p3self.matchbox import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(trn,val_dataset=val,batch_size=BS,print_on=5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def argmax(x):\n",
    "    return torch.max(x,dim=1)[1]\n",
    "\n",
    "def accuracy(y_pred,y_true):\n",
    "    return (argmax(y_pred)==y_true).float().mean()\n",
    "\n",
    "def save_model(model,path):\n",
    "    \"\"\"\n",
    "    model:pytorch model\n",
    "    path:save to path, end with pkl\n",
    "    \"\"\"\n",
    "    torch.save(model.state_dict(), path)\n",
    "    \n",
    "def load_model(model,path):\n",
    "    model.load_state_dict(torch.load(path))\n",
    "\n",
    "def save_():\n",
    "    save_model(dense_conv2,\"/data/weights/dense_conv2.%s.pkl\"%(VERSION))\n",
    "    save_model(top_half_,\"/data/weights/top_half.%s.pkl\"%(VERSION))\n",
    "    \n",
    "def load_():\n",
    "    load_model(dense_conv2,\"/data/weights/dense_conv2.%s.pkl\"%(VERSION))\n",
    "    load_model(top_half_,\"/data/weights/top_half.%s.pkl\"%(VERSION))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def action(*args,**kwargs):\n",
    "    x,y = args[0]\n",
    "    if CUDA:\n",
    "        x,y = x.cuda(),y.cuda()\n",
    "    x = x[:,:3,...]\n",
    "    opt.zero_grad()\n",
    "    y_ = top_half_(dense_conv2(dense_conv1(x)))\n",
    "    \n",
    "    loss = loss_func(y_,y)\n",
    "    acc = accuracy(y_,y)\n",
    "    \n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    if kwargs[\"ite\"]%10==9:\n",
    "        save_()\n",
    "    return {\n",
    "        \"loss\":loss.item(),\n",
    "        \"acc\":acc.item(),\n",
    "    }\n",
    "    \n",
    "def val_action(*args,**kwargs):\n",
    "    x,y = args[0]\n",
    "    if CUDA:\n",
    "        x,y = x.cuda(),y.cuda()\n",
    "    x = x[:,:3,...]\n",
    "    y_ = top_half_(dense_conv2(dense_conv1(x)))\n",
    "    \n",
    "    loss = loss_func(y_,y)\n",
    "    acc = accuracy(y_,y)\n",
    "\n",
    "    return {\n",
    "        \"loss\":loss.item(),\n",
    "        \"acc\":acc.item(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer.action = action\n",
    "trainer.val_action = val_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2408 [00:00<?, ?it/s]/home/zhangxiaochen/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if sys.path[0] == '':\n",
      "⭐[ep_0_i_129]\tacc\t0.919✨\tloss\t1.335:   6%|▌         | 133/2408 [01:14<21:16,  1.78it/s]/home/zhangxiaochen/anaconda3/lib/python3.6/site-packages/PIL/Image.py:885: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  'to RGBA images')\n",
      "⭐[ep_0_i_1839]\tacc\t1.000✨\tloss\t1.165:  76%|███████▋  | 1841/2408 [16:02<04:56,  1.91it/s]"
     ]
    }
   ],
   "source": [
    "trainer.train(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
